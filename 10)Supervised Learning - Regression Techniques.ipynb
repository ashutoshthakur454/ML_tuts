{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce19db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65390063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fec8ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function make_regression in module sklearn.datasets._samples_generator:\n",
      "\n",
      "make_regression(n_samples=100, n_features=100, *, n_informative=10, n_targets=1, bias=0.0, effective_rank=None, tail_strength=0.5, noise=0.0, shuffle=True, coef=False, random_state=None)\n",
      "    Generate a random regression problem.\n",
      "    \n",
      "    The input set can either be well conditioned (by default) or have a low\n",
      "    rank-fat tail singular profile. See :func:`make_low_rank_matrix` for\n",
      "    more details.\n",
      "    \n",
      "    The output is generated by applying a (potentially biased) random linear\n",
      "    regression model with `n_informative` nonzero regressors to the previously\n",
      "    generated input and some gaussian centered noise with some adjustable\n",
      "    scale.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <sample_generators>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    n_samples : int, default=100\n",
      "        The number of samples.\n",
      "    \n",
      "    n_features : int, default=100\n",
      "        The number of features.\n",
      "    \n",
      "    n_informative : int, default=10\n",
      "        The number of informative features, i.e., the number of features used\n",
      "        to build the linear model used to generate the output.\n",
      "    \n",
      "    n_targets : int, default=1\n",
      "        The number of regression targets, i.e., the dimension of the y output\n",
      "        vector associated with a sample. By default, the output is a scalar.\n",
      "    \n",
      "    bias : float, default=0.0\n",
      "        The bias term in the underlying linear model.\n",
      "    \n",
      "    effective_rank : int, default=None\n",
      "        If not None:\n",
      "            The approximate number of singular vectors required to explain most\n",
      "            of the input data by linear combinations. Using this kind of\n",
      "            singular spectrum in the input allows the generator to reproduce\n",
      "            the correlations often observed in practice.\n",
      "        If None:\n",
      "            The input set is well conditioned, centered and gaussian with\n",
      "            unit variance.\n",
      "    \n",
      "    tail_strength : float, default=0.5\n",
      "        The relative importance of the fat noisy tail of the singular values\n",
      "        profile if `effective_rank` is not None. When a float, it should be\n",
      "        between 0 and 1.\n",
      "    \n",
      "    noise : float, default=0.0\n",
      "        The standard deviation of the gaussian noise applied to the output.\n",
      "    \n",
      "    shuffle : bool, default=True\n",
      "        Shuffle the samples and the features.\n",
      "    \n",
      "    coef : bool, default=False\n",
      "        If True, the coefficients of the underlying linear model are returned.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, default=None\n",
      "        Determines random number generation for dataset creation. Pass an int\n",
      "        for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    X : ndarray of shape (n_samples, n_features)\n",
      "        The input samples.\n",
      "    \n",
      "    y : ndarray of shape (n_samples,) or (n_samples, n_targets)\n",
      "        The output values.\n",
      "    \n",
      "    coef : ndarray of shape (n_features,) or (n_features, n_targets)\n",
      "        The coefficient of the underlying linear model. It is returned only if\n",
      "        coef is True.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(make_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41421bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_regression(n_samples = 500,n_features = 100, n_informative = 10, noise = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb7e7e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f31ba3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5da20ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "283a8ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69426939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e36290b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  9.530230806499496\n",
      "MSE:  124.86939875160856\n",
      "r2 score:  0.9945433549839969\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "predictions = lr.predict(x_test)\n",
    "print(\"MAE: \", mean_absolute_error(y_test,predictions))\n",
    "print(\"MSE: \", mean_squared_error(y_test,predictions))\n",
    "print(\"r2 score: \",r2_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2966e27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  115.89404342431976\n",
      "MSE:  20780.175589037302\n",
      "r2 score:  0.091930907866827\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Generate polynomial features\n",
    "degree = 2  # Adjust the degree of the polynomial as needed\n",
    "poly_features = PolynomialFeatures(degree=degree)\n",
    "x_poly = poly_features.fit_transform(x_train)\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Create a pipeline with polynomial features and linear regression\n",
    "pipeline = make_pipeline(poly_features, model)\n",
    "\n",
    "# Fit the model to the data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = pipeline.predict(x_test)\n",
    "print(\"MAE: \", mean_absolute_error(y_test,predictions))\n",
    "print(\"MSE: \", mean_squared_error(y_test,predictions))\n",
    "print(\"r2 score: \",r2_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01acf0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  114.7230506100953\n",
      "MSE:  19572.86997667257\n",
      "r2 score:  0.14468873499152624\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(x_train,y_train)\n",
    "predictions = tree.predict(x_test)\n",
    "print(\"MAE: \", mean_absolute_error(y_test,predictions))\n",
    "print(\"MSE: \", mean_squared_error(y_test,predictions))\n",
    "print(\"r2 score: \",r2_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44a2500b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  63.93442260922396\n",
      "MSE:  6366.7983229931015\n",
      "r2 score:  0.7217784446438743\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfg = RandomForestRegressor()\n",
    "rfg.fit(x_train,y_train)\n",
    "predictions = rfg.predict(x_test)\n",
    "print(\"MAE: \", mean_absolute_error(y_test,predictions))\n",
    "print(\"MSE: \", mean_squared_error(y_test,predictions))\n",
    "print(\"r2 score: \",r2_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f05f68c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  9.481951120061359\n",
      "MSE:  123.90570827262984\n",
      "r2 score:  0.9945854671179678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge()\n",
    "ridge.fit(x_train,y_train)\n",
    "predictions = ridge.predict(x_test)\n",
    "print(\"MAE: \", mean_absolute_error(y_test,predictions))\n",
    "print(\"MSE: \", mean_squared_error(y_test,predictions))\n",
    "print(\"r2 score: \",r2_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75a6c9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  8.879266630235904\n",
      "MSE:  113.80201065803278\n",
      "r2 score:  0.9950269867519461\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso()\n",
    "lasso.fit(x_train,y_train)\n",
    "predictions = lasso.predict(x_test)\n",
    "print(\"MAE: \", mean_absolute_error(y_test,predictions))\n",
    "print(\"MSE: \", mean_squared_error(y_test,predictions))\n",
    "print(\"r2 score: \",r2_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e46701b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  10.439704957376417\n",
      "MSE:  164.3580149110773\n",
      "r2 score:  0.9928177491693646\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svc = SVR(kernel = 'linear')\n",
    "svc.fit(x_train,y_train)\n",
    "predictions = svc.predict(x_test)\n",
    "print(\"MAE: \", mean_absolute_error(y_test,predictions))\n",
    "print(\"MSE: \", mean_squared_error(y_test,predictions))\n",
    "print(\"r2 score: \",r2_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb45d33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  11.271980126375459\n",
      "MSE:  197.90464887812618\n",
      "r2 score:  0.9913518009477021\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "model = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "model.fit(x_train,y_train)\n",
    "predictions = model.predict(x_test)\n",
    "print(\"MAE: \", mean_absolute_error(y_test,predictions))\n",
    "print(\"MSE: \", mean_squared_error(y_test,predictions))\n",
    "print(\"r2 score: \",r2_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eca8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
